#!/usr/bin/python3
# encoding = UTF-8

import os
import random
import numpy as np
import argparse
import scipy as sp
import pyfaidx
import gzip
from SequenceContainer import ReadContainer

# Parsing all input arguments

parser = argparse.ArgumentParser(description='RNASeqDesigner Version 1')
# parser.add_argument('-h', type=int, required=True, default=100, metavar='<i>', help='help function')
parser.add_argument('-r',           type=int,        required=True,      default=100,        metavar='<int>',           help='Read length')
parser.add_argument('-n',           type=int,        required=True,      default=100,        metavar='<int>',           help='Number of reads to simulate')
parser.add_argument('-f',           type=str,        required=True,                          metavar='<str>',           help='Reference transcriptome file')
parser.add_argument('-s',           type=int,        required=False,     default=1223,       metavar='<int>',           help='Random seed for reproducibility')
parser.add_argument('-o',           type=str,        required=True,                          metavar='<str>',           help='Output prefix')
parser.add_argument('-seqmodel',    type=str,        required=True,                          metavar='<str>',           help='Sequencing_model')
parser.add_argument('-er',          type=float,      required=False,     default=-1,         metavar='<int>',           help='Error rate')


parser.add_argument('-p', type=int,   required=False, metavar='<int>',   default=2,     help="ploidy")
parser.add_argument('-m', type=str,   required=False, metavar='<str>',   default=None,  help="mutation model pickle file")
parser.add_argument('-M', type=float, required=False, metavar='<float>', default=-1,    help="rescale avg mutation rate to this")


args = parser.parse_args()

ref = args.f
readlen = args.r
readtot = args.n
SEED = args.s
output = args.o
sqmodel = args.seqmodel
SE_RATE = args.er
PLOIDS = args.p
MUT_MODEL = args.m
MUT_RATE = args.M

# Handling Reference if file is gzip compressed

# gzip_magic_number =  "1f8b"
# Ref = open(ref, 'r')
# if Ref.read(2).encode('hex') == gzip_magic_number:
#     ref = gzip.open(Ref, 'rb')
# else:
#     ref = open(ref, 'rb')


# Create index from input fasta file
pyfaidx.Faidx(ref)

# Search curdir for index file and read into programme
indexFile = ''
for file in os.listdir('.'):
    if file.endswith('.fai'):
        indexFile = (os.path.join('.', file))

SE_CLASS = ReadContainer(readlen, sqmodel, SE_RATE)

def normdist(low, high=None):
    """"
    Description
    This function generates random numbers according to a specified distribution
    Parameters
    low (int): The lowest value to sample
    high (int) the upper bound for sampling
    Return: Returns a vector of numbers drawn from a user-specified distribution
    """

    np.random.seed(SEED)
    counts = np.round(np.random.uniform(low=0, high=high, size=readtot))
    # counts = np.round(sp.random.normal(loc=5000, scale=500, size=readtot))
    # counts = np.round(sp.random.negative_binomial(n=1, p=0.1, size=10000))
    return counts

# sampling from the index file

def parseIndexRef(indexFile):
    """
    Description:
    Read in sequence data from reference index FASTA file returns a list of transcript IDs
    offset, seqLen, position
    Parameters
     - indexFile (str): The index file generated by the program, written to the current directory
    Return: The function returns a list of tuples containing the transcript id, start and end offset of the transcript sequence
    """
    ref_inds = []
    fai = open(indexFile, 'r')
    for line in fai:
        splt = line[:-1].split('\t')
        header = '@' + splt[0]
        seqLen = int(splt[1])
        offset = int(splt[2])
        lineLn = int(splt[3])
        nLines = seqLen / lineLn
        if seqLen % lineLn != 0:
            nLines += 1
        ref_inds.append((header, offset, offset+seqLen+nLines))
    fai.close()
    return ref_inds

def samplingtranscripts(ids):
    """"
    Description: This function randomly sample from all reference transcripts
    Parameters: ids (list of tuples) It takes as input all reference transcripts offsets
    Returns: This function returns a subset of transcript ids to be written to be sampled from
    """
    random.seed(SEED)
    numreads = readtot
    sampledtranscripts = random.sample(ids, numreads)

    return sampledtranscripts

def getseq(key, start=1, end=None):
    """
    Description
    Get a sequence by key coordinates are 1-based and end is inclusive
    Parameters:
        key:
        start:
        end:
    Returns:
    """

    if end != None and end < start:
        return ""
    start -= 1
    seek = start

    # if seek is past sequence then return empty sequence
    if seek >= end:
        return ""

    # seek to beginning
    infile = open(ref, 'r')
    infile.seek(seek)

    # read until end of sequence
    header = ''
    seq = []
    if end == None:
        lenNeeded = util.INF
    else:
        lenNeeded = end - start

    len2 = 0
    while len2 < lenNeeded:
        line = infile.readline()
        if line.startswith(">") or len(line) == 0:
            break
        seq.append(header + line.rstrip())
        len2 += len(seq[-1])
        if len2 > lenNeeded:
            seq[-1] = seq[-1][:-int(len2 - lenNeeded)]
            break
    seq = "".join(seq)
    return seq

def processTransIDs(ids):
    """"
    Description:
    This function take as input a list of transcript ids and converts it to a dictionar
    Parameters:
        ids (list of tuples): List of transcript ids
    Returns: The function returns a dictionary of transcript id as key and start and end position as value
    """

    Transseq = []
    header = []
    transcriptID = {i: [j, k] for i, j, k in ids}
    ID = transcriptID.keys()
    for k in ID:
        header.append(k)
    pos = transcriptID.values()
    for i in pos:
        start = i[0]
        end = i[1]
        seq = getseq(ID, start, end)
        Transseq.append(seq)
    new_dict = {k: v for k, v in zip(header, Transseq)}
    return new_dict

def GenerateRead(seq, readLen):
    """
    Description:
    This function truncates transcript sequences by a specified read length.
    Parameters:
    :param seq: Transcript sequence randomly sampled from the input reference transcriptome file
    :param readLen: The user-specified read length

    :return: The function returns a list of all truncated sequences
    """
    read = []
    seqLen = len(seq)
    endmax = seqLen - (readLen + 1)
    startpos = np.sort(normdist(low=0, high=endmax))
    endpos = [i + readLen for i in startpos]
    for i, j in zip(startpos, endpos):
        read = np.array(seq[int(i):int(j)])
    return read

def sample_qualscore(sequencingModel):
    (myQual, myErrors) = SE_CLASS.getSequencingErrors(sequencingModel)
    return myQual

def main():

    f = []
    ids = []
    qstrings = []

    transcriptIDs = parseIndexRef(indexFile)
    print('Converting reference to index file')
    s = samplingtranscripts(transcriptIDs)
    # print(s)
    print('Random sampling from transcript file')

    p = processTransIDs(s)

    for key, value in p.items():
        finalseq = GenerateRead(value, readlen)
        f.append(finalseq)
        ids.append(key)

    for i in f:
        qdata = sample_qualscore(sequencingModel=sqmodel)
        qstrings.append(qdata)

    reads = zip(ids, f, qstrings)

    with open(output, 'w') as handle:
        for k, v, i in reads:
            handle.write('{}\n{}\n+\n{}\n'.format(k, v, i))
    print('Writing output to file')


if __name__ == '__main__':
    main()























